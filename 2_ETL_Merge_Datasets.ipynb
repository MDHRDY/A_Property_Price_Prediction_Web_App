{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Price Prediction Web App - ETL Notebook 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central steps in the ETL process for this project are:  \n",
    "1. convert state plane coordinates, from the Dep. of City Planning, into standard Lat Long coordinates (Notebook 1)\n",
    "2. aggregate ~ 60 Dep. of Finance sales data sets - spread across five boroughs and twelve years (This notebook)\n",
    "3. Merge the Dep. of Finance and Dep. of City Planning Datasets (This notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations of the three sources: \n",
    "1. NYC Dep. of City Planning (has GPS coordinates for all NYC properties):  \n",
    "   http://www1.nyc.gov/site/planning/data-maps/open-data/dwn-pluto-mappluto.page\n",
    "2. NYC Dep. of Finance (tracks sales of all NYC properties):  \n",
    "   https://www1.nyc.gov/site/finance/taxes/property-annualized-sales-update.page\n",
    "3. NYTimes Real Estate Section (current listings on the market):      \n",
    "   https://www.nytimes.com/section/realestate  \n",
    "   The web scraper I built to pull listings off of the nytimes website: \n",
    "   https://github.com/MDHRDY/A_NY_Times_Real_Estate_Web_Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate  Annualized Sales Datasets from the Dep. of Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "1 [Load Libraries and Dep. of Finance dataset, and Merge datasets](#load)  \n",
    "2 [Save dataframe w/ converted coordinates to file](#to_file)  \n",
    "3 [Load Dep of City Planning dataset and Merge with Sales dataset](#merge)  \n",
    "4 [Merge Datasets and Save to File](#to_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load'></a>\n",
    "### Load Libraries and Dep. of Finance datasets, and Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "options.display.max_columns = 100\n",
    "options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load one dataset to initialize columns for master dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/Users/michaelhardy/mdh_python/nyc_project/Annualized_nyc_sales/\"\n",
    "df_init = pd.read_excel(path + '2003_Bronx.xls')\n",
    "df_mast = DataFrame(columns=df_init.iloc[2])\n",
    "\n",
    "# initialize colums \n",
    "mast_columns = df_init.iloc[2].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open all downloaded files and merge into master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total lines:  1254059\n"
     ]
    }
   ],
   "source": [
    "dates = map(str, range(2003,2016))\n",
    "boroughs = ['_bronx.xls', '_brooklyn.xls', '_manhattan.xls', \n",
    "                            '_queens.xls', '_statenisland.xls']\n",
    "\n",
    "total_length = 0\n",
    "adjust = 0\n",
    "\n",
    "for date in dates:\n",
    "    for borough in boroughs:\n",
    "        f = date + borough\n",
    "        df_temp = read_excel(path + f)\n",
    "        \n",
    "        # since 2011, xls files have had extra row in header\n",
    "        if date == '2011': adjust = 1\n",
    "        df_temp.columns = df_temp.iloc[2 + adjust]\n",
    "        df_temp = df_temp.ix[3:, :]\n",
    "        df_temp.columns = mast_columns\n",
    "        \n",
    "        df_temp.columns = mast_columns\n",
    "        df_mast = df_mast.append(df_temp)\n",
    "\n",
    "        # reporting ...\n",
    "        #print f, df_temp.shape[0]\n",
    "        total_length += df_temp.shape[0]\n",
    "        \n",
    "print \"total lines: \", total_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master dataframe size:  (1254059, 21)\n"
     ]
    }
   ],
   "source": [
    "print \"master dataframe size: \", df_mast.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='to_file'></a>\n",
    "### Write results to file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_mast.to_csv('all_sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='merge'></a>\n",
    "\n",
    "### Load Dep of City Planning dataset and match columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPS Coordinates dataset (from Notebook1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834182, 89)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path2 = \"/Users/michaelhardy/mdh_python/nyc_project/\"\n",
    "df_lat_long = read_csv(path2 + 'Post_DI/csvs/All_tax_classes_Lat_Long_w_89_variables.csv', low_memory=False)\n",
    "df_lat_long.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merged Sales dataset (from above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sales Dataframe:  (1254059, 21)\n"
     ]
    }
   ],
   "source": [
    "sales = read_csv('all_sales.csv', low_memory=False)\n",
    "print \"Shape of Sales Dataframe: \", sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe three columns (Block, Borough and Lot) to merge datasets on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat long dataframe format:  ['Borough', 'Block', 'Lot']\n",
      "sales dataframe format:  ['BOROUGH', 'NEIGHBORHOOD', 'BUILDING CLASS CATEGORY', 'TAX CLASS AT PRESENT', 'BLOCK', 'LOT']\n"
     ]
    }
   ],
   "source": [
    "print 'lat long dataframe format: ',df_lat_long.columns.tolist()[0:3]\n",
    "print 'sales dataframe format: ',sales.columns.tolist()[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert column names from df_lat_long to caps to match column format in sales dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ll_columns = df_lat_long.columns.tolist()\n",
    "ll_columns[71] = 'BOROUGH'\n",
    "ll_columns[1] = 'BLOCK'\n",
    "ll_columns[2] = 'LOT'\n",
    "df_lat_long.columns = ll_columns\n",
    "df_lat_long.LOT = df_lat_long.LOT.astype(str)\n",
    "df_lat_long.BOROUGH = df_lat_long.BOROUGH.astype(str)\n",
    "df_lat_long.BLOCK = df_lat_long.BLOCK.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check 'Borough' for null values:  0\n"
     ]
    }
   ],
   "source": [
    "print \"Check 'Borough' for null values: \", sales.BOROUGH.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='to_file'></a>\n",
    "\n",
    "### Merge Datasets and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928790, 107)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_89 = sales.merge(df_lat_long,how='inner', left_on = ['BOROUGH','BLOCK', 'LOT'], right_on = ['BOROUGH','BLOCK', 'LOT'])\n",
    "df_89.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_89.to_csv('merge_sales_and_gps_datasets_107_features_11_8_16.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
